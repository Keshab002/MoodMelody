{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9f723f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-12 15:25:13.268498: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-12 15:25:13.934938: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/roronoa/.conda/envs/tf/lib/python3.7/site-packages/nvidia/cudnn/lib:/home/roronoa/.conda/envs/tf/lib/:\n",
      "2023-11-12 15:25:13.935014: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/roronoa/.conda/envs/tf/lib/python3.7/site-packages/nvidia/cudnn/lib:/home/roronoa/.conda/envs/tf/lib/:\n",
      "2023-11-12 15:25:13.935023: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8108012d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the image dimensions and batch size\n",
    "img_size = (224, 224)\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef051707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data generators for training and testing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c81c7390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21077 images belonging to 4 classes.\n",
      "Found 5140 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = train_datagen.flow_from_directory(\n",
    "    '../Data/images/train',\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_data = test_datagen.flow_from_directory(\n",
    "    '../Data/images/test',\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc92f4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-12 15:25:15.438424: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-12 15:25:15.461993: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-12 15:25:15.462281: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-12 15:25:15.462893: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-12 15:25:15.463543: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-12 15:25:15.463731: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-12 15:25:15.463901: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-12 15:25:15.513811: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-12 15:25:15.514033: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-12 15:25:15.514217: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-12 15:25:15.514359: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1212 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Create the InceptionV3 base model\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Add custom layers for classification\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(64, activation='relu')(x)  # Additional dense layer\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(4, activation='softmax')(x)\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3cb5fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the layers of the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10f2b9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-12 15:25:21.941713: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8500\n",
      "2023-11-12 15:25:22.230273: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-11-12 15:25:22.846869: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 666.04MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-11-12 15:25:22.846959: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 666.04MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-11-12 15:25:22.904802: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 898.14MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-11-12 15:25:22.904830: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 898.14MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-11-12 15:25:22.905069: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 387.28MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-11-12 15:25:22.905086: W tensorflow/core/kernels/gpu_utils.cc:50] Failed to allocate memory for convolution redzone checking; skipping this check. This is benign and only means that we won't check cudnn for out-of-bounds reads and writes. This message will only be printed once.\n",
      "2023-11-12 15:25:23.826399: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.03GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-11-12 15:25:23.826487: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.03GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-11-12 15:25:23.918189: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.31GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-11-12 15:25:23.918226: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.31GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-11-12 15:25:24.065484: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 383.93MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-11-12 15:25:27.270560: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-11-12 15:25:27.294431: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x55883a552be0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-12 15:25:27.294457: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Laptop GPU, Compute Capability 8.6\n",
      "2023-11-12 15:25:27.297956: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-11-12 15:25:27.352183: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-11-12 15:25:27.385976: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 [==============================] - 141s 802ms/step - loss: 1.7475 - accuracy: 0.3075\n",
      "Epoch 2/50\n",
      "165/165 [==============================] - 128s 772ms/step - loss: 1.4091 - accuracy: 0.3664\n",
      "Epoch 3/50\n",
      "165/165 [==============================] - 127s 769ms/step - loss: 1.3153 - accuracy: 0.3962\n",
      "Epoch 4/50\n",
      "165/165 [==============================] - 127s 767ms/step - loss: 1.2821 - accuracy: 0.4117\n",
      "Epoch 5/50\n",
      "165/165 [==============================] - 127s 770ms/step - loss: 1.2614 - accuracy: 0.4282\n",
      "Epoch 6/50\n",
      "165/165 [==============================] - 127s 767ms/step - loss: 1.2513 - accuracy: 0.4322\n",
      "Epoch 7/50\n",
      "165/165 [==============================] - 128s 771ms/step - loss: 1.2348 - accuracy: 0.4465\n",
      "Epoch 8/50\n",
      "165/165 [==============================] - 129s 782ms/step - loss: 1.2251 - accuracy: 0.4529\n",
      "Epoch 9/50\n",
      "165/165 [==============================] - 128s 772ms/step - loss: 1.2223 - accuracy: 0.4550\n",
      "Epoch 10/50\n",
      "165/165 [==============================] - 127s 766ms/step - loss: 1.2208 - accuracy: 0.4547\n",
      "Epoch 11/50\n",
      "165/165 [==============================] - 127s 770ms/step - loss: 1.2211 - accuracy: 0.4544\n",
      "Epoch 12/50\n",
      "165/165 [==============================] - 126s 759ms/step - loss: 1.2173 - accuracy: 0.4562\n",
      "Epoch 13/50\n",
      "165/165 [==============================] - 126s 760ms/step - loss: 1.2122 - accuracy: 0.4589\n",
      "Epoch 14/50\n",
      "165/165 [==============================] - 127s 771ms/step - loss: 1.2084 - accuracy: 0.4616\n",
      "Epoch 15/50\n",
      "165/165 [==============================] - 127s 765ms/step - loss: 1.2046 - accuracy: 0.4703\n",
      "Epoch 16/50\n",
      "165/165 [==============================] - 125s 754ms/step - loss: 1.2084 - accuracy: 0.4624\n",
      "Epoch 17/50\n",
      "165/165 [==============================] - 127s 766ms/step - loss: 1.2039 - accuracy: 0.4674\n",
      "Epoch 18/50\n",
      "165/165 [==============================] - 125s 755ms/step - loss: 1.2045 - accuracy: 0.4689\n",
      "Epoch 19/50\n",
      "165/165 [==============================] - 126s 761ms/step - loss: 1.1975 - accuracy: 0.4723\n",
      "Epoch 20/50\n",
      "165/165 [==============================] - 126s 763ms/step - loss: 1.1937 - accuracy: 0.4741\n",
      "Epoch 21/50\n",
      "165/165 [==============================] - 125s 756ms/step - loss: 1.1965 - accuracy: 0.4745\n",
      "Epoch 22/50\n",
      "165/165 [==============================] - 124s 751ms/step - loss: 1.1948 - accuracy: 0.4718\n",
      "Epoch 23/50\n",
      "165/165 [==============================] - 130s 783ms/step - loss: 1.1931 - accuracy: 0.4716\n",
      "Epoch 24/50\n",
      "165/165 [==============================] - 129s 778ms/step - loss: 1.1932 - accuracy: 0.4770\n",
      "Epoch 25/50\n",
      "165/165 [==============================] - 130s 786ms/step - loss: 1.1880 - accuracy: 0.4782\n",
      "Epoch 26/50\n",
      "165/165 [==============================] - 130s 787ms/step - loss: 1.1907 - accuracy: 0.4780\n",
      "Epoch 27/50\n",
      "165/165 [==============================] - 129s 782ms/step - loss: 1.1930 - accuracy: 0.4727\n",
      "Epoch 28/50\n",
      "165/165 [==============================] - 130s 784ms/step - loss: 1.1909 - accuracy: 0.4771\n",
      "Epoch 29/50\n",
      "165/165 [==============================] - 130s 783ms/step - loss: 1.1931 - accuracy: 0.4787\n",
      "Epoch 30/50\n",
      "165/165 [==============================] - 130s 785ms/step - loss: 1.1858 - accuracy: 0.4816\n",
      "Epoch 31/50\n",
      "165/165 [==============================] - 130s 786ms/step - loss: 1.1869 - accuracy: 0.4773\n",
      "Epoch 32/50\n",
      "165/165 [==============================] - 130s 783ms/step - loss: 1.1914 - accuracy: 0.4753\n",
      "Epoch 33/50\n",
      "165/165 [==============================] - 129s 782ms/step - loss: 1.1821 - accuracy: 0.4855\n",
      "Epoch 34/50\n",
      "165/165 [==============================] - 129s 782ms/step - loss: 1.1850 - accuracy: 0.4808\n",
      "Epoch 35/50\n",
      "165/165 [==============================] - 129s 780ms/step - loss: 1.1833 - accuracy: 0.4822\n",
      "Epoch 36/50\n",
      "165/165 [==============================] - 129s 780ms/step - loss: 1.1832 - accuracy: 0.4803\n",
      "Epoch 37/50\n",
      "165/165 [==============================] - 129s 781ms/step - loss: 1.1857 - accuracy: 0.4799\n",
      "Epoch 38/50\n",
      "165/165 [==============================] - 130s 788ms/step - loss: 1.1855 - accuracy: 0.4798\n",
      "Epoch 39/50\n",
      "165/165 [==============================] - 130s 785ms/step - loss: 1.1765 - accuracy: 0.4875\n",
      "Epoch 40/50\n",
      "165/165 [==============================] - 129s 782ms/step - loss: 1.1751 - accuracy: 0.4849\n",
      "Epoch 41/50\n",
      "165/165 [==============================] - 131s 789ms/step - loss: 1.1769 - accuracy: 0.4894\n",
      "Epoch 42/50\n",
      "165/165 [==============================] - 130s 785ms/step - loss: 1.1791 - accuracy: 0.4828\n",
      "Epoch 43/50\n",
      "165/165 [==============================] - 130s 784ms/step - loss: 1.1784 - accuracy: 0.4853\n",
      "Epoch 44/50\n",
      "165/165 [==============================] - 127s 766ms/step - loss: 1.1765 - accuracy: 0.4854\n",
      "Epoch 45/50\n",
      "165/165 [==============================] - 128s 774ms/step - loss: 1.1820 - accuracy: 0.4809\n",
      "Epoch 46/50\n",
      "165/165 [==============================] - 130s 787ms/step - loss: 1.1741 - accuracy: 0.4931\n",
      "Epoch 47/50\n",
      "165/165 [==============================] - 130s 783ms/step - loss: 1.1806 - accuracy: 0.4848\n",
      "Epoch 48/50\n",
      "165/165 [==============================] - 129s 779ms/step - loss: 1.1763 - accuracy: 0.4832\n",
      "Epoch 49/50\n",
      "165/165 [==============================] - 131s 789ms/step - loss: 1.1783 - accuracy: 0.4867\n",
      "Epoch 50/50\n",
      "165/165 [==============================] - 130s 785ms/step - loss: 1.1765 - accuracy: 0.4883\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "epochs = 50\n",
    "history = model.fit(train_data, epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53658d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 17s 409ms/step\n",
      "F1 Score: 0.5574\n",
      "Accuracy: 0.5623\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.47      0.33      0.39       960\n",
      "       happy       0.70      0.72      0.71      1825\n",
      "     neutral       0.50      0.54      0.52      1216\n",
      "         sad       0.47      0.52      0.49      1139\n",
      "\n",
      "    accuracy                           0.56      5140\n",
      "   macro avg       0.54      0.53      0.53      5140\n",
      "weighted avg       0.56      0.56      0.56      5140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict class labels for the test data\n",
    "y_pred = model.predict(test_data)\n",
    "y_true = test_data.labels\n",
    "\n",
    "# Calculate F1 score and classification report\n",
    "f1 = f1_score(y_true, y_pred.argmax(axis=1), average='weighted')\n",
    "accuracy = accuracy_score(y_true, y_pred.argmax(axis=1))\n",
    "report = classification_report(y_true, y_pred.argmax(axis=1), target_names=train_data.class_indices.keys())\n",
    "\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a273d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
